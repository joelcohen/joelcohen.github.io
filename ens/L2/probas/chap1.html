---
layout: default
permalink: /ens/L2/probas/chap1
title: Probabilités - Chapitre 1
hidden : True
---
<script type="text/javascript">
<!--
    function toggle_visibility(id) {
       var elt = document.getElementById(id);
       if(elt.style.display == 'block')
          elt.style.display = 'none';
       else
          elt.style.display = 'block';
    }
//-->
</script>
<div class="exomath">
    <div class="titlebox">
        <h2>Chapitre 1</h2>
        <h1>Événements</h1>
    </div>
    <section>
       <h2>Univers et événements</h2>
       <p>On parlera d'une <strong class="new">expérience aléatoire</strong> pour une expérience dont on ne connaît pas le résultat avec certitude a priori. À une expérience aléatoire, on associe l'ensemble des issues possibles, qu'on appelle l'<strong class="new">univers</strong> de cette expérience aléatoire et qui est le plus souvent noté par la lettre $\Omega$ majuscule (on parle parfois aussi de population pour l'ensemble $\Omega$, notamment en statistiques). Un élément de l'ensemble $\Omega$ (que l'on note souvent $\omega$ minuscule) est un des résultats possibles de l'expérience.</p>
       <article class="exemple">
           <p>Si on lance une pièce de monnaie, l'univers sera l'ensemble $\Omega = \{\pile, \face\}$, et $\omega = \face$ est un résultat possible.</p>
       </article>
       <article class="exemple">
           <p>Si on lance un dé à 6 faces, l'univers sera l'ensemble $\Omega = \ints{1,6} = \{1,2,3,4,5,6\}$ des valeurs possibles du dé, et $\omega = 5$ est un résultat possible.</p>
       </article>
       <article class="exemple">
           <p>Si on lance une pièce de monnaie deux fois, l'univers sera l'ensemble des couples de résultats $\Omega = \{\pile, \face\}^2 = \{(\pile,\pile), (\pile,\face), (\face,\pile), (\face,\face)\}$, et $\omega = (\face, \pile)$ est un résultat possible.</p>
       </article>
       <article class="exemple">Si on tire au hasard une carte dans un paquet de 52 cartes, l'univers sera l'ensemble des 52 valeurs possibles de cartes, qu'on peut voir comme un couple contenant la valeur de la carte (de 1 à 13), et la couleur (coeur, pique, carreau ou trèfle), c'est-à-dire
       $$\Omega = \ints{1,13} \times \set{\color{red}{\heartsuit}, \spadesuit, \color{red}{\diamondsuit}, \clubsuit}$$
       </article>
       <p>Pour d'autres exemples et pour s'exercer sur la notion d'univers, voir la <a href="td1#univers">feuille 1 exercice 1</a>.</p>
       
       <article class="definition">
           <p>Étant donnée une expérience aléatoire ayant pour univers $\Omega$, un <strong class="new">événement aléatoire</strong> (ou juste événement) $E$ est un ensemble de résultats possibles de l'expérience, c'est-à-dire une partie de l'univers : $E \subset \Omega$.</p>
           <p>On dit qu'un événement $E$ se <strong class="new">réalise</strong> si le résultat $\omega$ de l'expérience appartient à l'ensemble $E$ : $\omega \in E$</p>
           <p>L'ensemble $\mathcal{A}$ de tous les événements est appelé une <strong class="new">tribu</strong>. Le couple $(\Omega, \mathcal{A})$ est appelé un <strong class="new">espace probabilisable</strong>.</p>
       </article>
       <p>La définition ci-dessus de tribu est délibérément vague pour cacher la complexité sous-jacente et dont les subtilités dépassent la portée de ce cours. À titre culturel, nous donnons quand même la définition rigoureuse.</p>
       
       <article class="definition" id="tribu"><strong>Tribu</strong>
           <p>Soit $\Omega$ un ensemble et $\mathcal{A} \subset \Omega$ un ensemble de parties de $\Omega$. On dit que $\mathcal{A}$ est une <strong class="new">tribu</strong> sur $\Omega$ si</p>
           <ol>
               <li><strong>Stable par complémentaire :</strong> Pour toute partie $A \in \mathcal{A}$, le complémentaire est encore dans $\mathcal{A}$ :
                   $$\overline{A} \in \mathcal{A}$$
               </li>
               <li><strong>Stable par union (dénombrable):</strong> Pour toute suite $(A_n)_{n \in \N} \in \mathcal{A}^{\N}$ de partie de $\mathcal{A}$, l'union est encore dans $\mathcal{A}$ :
               $$\bigcap_{n \in \N} A_n \in \mathcal{A}$$
               </li>
           </ol>
           <p>Si $\mathcal{A}$ est une tribu sur $\Omega$, le couple $(\Omega, \mathcal{A})$ est appelé un <strong class="new">espace probabilisable</strong>.</p>
       </article>
       
       <p>Dans ce cours, l'univers $\Omega$ sera fini le plus souvent, et la tribu $\mathcal{A}$ sera pratiquement toujours l'ensemble $\mathcal{P}(\Omega)$ de toutes les parties de $\Omega$. On peut donc se permettre de ne pas trop se soucier de la question. Quand l'univers $\Omega$ est infini, des subtilités apparaissent et on peut être amenés à considérer des tribus plus petites, ne contenant pas toutes les parties de $\Omega$. Pour s'exercer sur la notion d'événement aléatoire, voir la <a href="td1#evenements">feuille 1 exercice 2</a>.</p>
    </section>
    
    <section>
        <h2>Probabilité</h2>
        <h3>Définition axiomatique</h3>
        <p>À titre culturel, on donne la définition axiomatique d'une probabilité.</p>
        <article class="definition" id="probabilité"><strong>Probabilité</strong>
            <p>Étant donné un univers $\Omega$ et une tribu $\mathcal{A}$ (c'est-à-dire un espace probabilisable), une <strong class="new">probabilité</strong> est une fonction qui à chaque événement associe une valeur numérique :</p>
            <p>
                $$\begin{align*}
                \P : \mathcal{A}    & \longrightarrow [0,1] \\
                                        A   & \longmapsto \P(A)
                \end{align*}$$
            </p>
            <p>satisfaisant les propriétés</p>
            <ol>
                <li>$\P(\Omega) = 1$</li>
                <li>Si $(A_n)_{n \ge 0}$ sont des événéments 2 à 2 disjoints (c'est-à-dire que $A_i \cap A_j = \emptyset$ pour tous $i \ne j$), alors
                $$\P\left(\bigcup_{i = 0}^{+\infty} A_i \right) = \sum_{i = 0}^{+\infty} \P(A_i)$$
                </li>
            </ol>
            <p>On dit que le triplet $(\Omega, \mathcal{A}, \P)$ forme un <strong class="new">espace probabilisé</strong>.</p>
        </article>
        <p>Ce cours ne fera pas vraiment appel dans la suite à cette définition formelle (mais on sera amené à utiliser les propriétes qui en découlent et que nous énonçons dans la suite). Notons que pour un espace probabilisable $(\Omega, \mathcal{A})$ donné, il y plusieurs façons de choisir une probabilité pour en faire un espace probabilisé. Décider laquelle on prend relève d'un choix de modélisation. Nous donnons quelques exemples qui illustrent cela.</p>
        <article class="exemple">
             <p>Pour le lancer d'une pièce de monnaie, on prend $\Omega = \{\pile, \face\}$ pour univers, et pour tribu l'ensemble des parties de $\Omega$:</p>
             <p>$$\mathcal{A} = \mathcal{P}(\Omega) = \{\emptyset, \{ \pile \}, \{ \face \}, \{ \pile, \face \} \} $$</p>
             <p>On peut définir une probabilité $ \P : \mathcal{A} \to [0,1]$ par</p>
             <p>
                 $$
                 \begin{align*}
                 \P :  \qquad \qquad \emptyset & \longmapsto 0 \\
                 \{ \pile \} & \longmapsto \frac{1}{2} \\
                 \{ \face \} & \longmapsto \frac{1}{2} \\
                 \{ \pile, \face \} & \longmapsto 1
                 \end{align*}
                 $$
             </p>
             <p>On vérifie que cette fonction est effectivement une probabilité selon notre définition, car on a bien</p>
             <p>
                 $$
                 \begin{align*}
                 \P(\{ \pile \} \cup \{ \face \}) &= \P(\{ \pile, \face \}) \\
                 &= 1 \\
                 &= \frac{1}{2} + \frac{1}{2} \\
                 &= \P(\{ \pile \}) + \P(\{ \face \})
                 \end{align*}
                 $$
             </p>
             <p>Si $p \in [0,1]$, on pourrait définir une autre fonction de probabilité $\P_p$ sur $\mathcal{A}$ en posant $\P_p(\set{\pile}) = p$ et $\P_p(\set{\face}) = 1-p$ (pour $p \ne 1/2$, cela correspondrait aux probabilités observées pour une pièce non équilibrée).</p>
        </article>
        <article class="exemple">
            <p>Pour le lancer d'un dé à 6 faces, on prend $\Omega = \{1,2,3,4,5,6\}$. On peut alors définir une fonction de probabilité, dite probabilité uniforme, en posant pour tout $A \subset \Omega$,</p>
            <p>$$\P(A) = \frac{|A|}{6}$$</p>
        </article>
        <h3>Univers fini équiprobable</h3>
        <p>Dans le cas où l'univers $\Omega$ est fini, le modèle le plus raisonnable est bien souvent d'attribuer une probabilité égale à tous les singletons s'il n'y a pas de raison de penser qu'un résultat est plus probable qu'un autre. C'est-à-dire que pour tout $\omega \in \Omega$, on pose</p>
        <p>$$\P(\{\omega\}) = \frac{1}{|\Omega|}$$</p>
        <p>et pour un événement $A \subset \Omega$, on a</p>
        <p>$$
            \begin{align*}
                 \P(A) = \frac{|A|}{|\Omega|}
            \end{align*}
            $$
        </p>
        <p>Ce que l'on retient souvent sous la forme : la probabilité d'un événement est le "nombre de cas favorables" divisé par le "nombre de cas total".</p>
        <h3>Propriétés générales</h3>
        <p>En conséquence de la définition générale d'une fonction de probabilité, nous avons les propriétes suivantes :</p>
        <article class="prop">
            Soient $A, B \in \mathcal{A}$ deux événements. On a
            <ol class="exo">
                <li>$\P(\Omega) = 1$ et $\P(\emptyset) = 0$</li>
                <li>$\P(\overline{A}) = 1 - \P(A)$</li>
                <li>Si $A \subset B$, alors $\P(A) \le \P(B)$</li>
                <li>$\P(A \cup B) = \P(A) + \P(B) - \P(A \cap B)$</li>
            </ol>
        </article>
        <p>Ici, $\overline{A}$ désigne le complémentaire de $A$. La propriété $\P(\overline{A}) = 1 - \P(A)$ peut se révéler très pratique dans certains cas pour lesquels il est plus facile de calculer la probabilité du complémentaire.</p>
    </section>
    <section>
        <h2>Événements indépendants</h2>
        <article class="definition" id="independant"><strong>Indépendance de deux événements</strong>
            <p>Étant donné un espace probabilisé $(\Omega, \mathcal{A}, \P)$, on dit que deux événements $A, B \in \mathcal{A}$ sont <strong class="new">indépendants</strong> si</p>
            <p>$$\P(A \cap B) = \P(A) \times \P(A)$$</p>
        </article>
        <p>Moralement, deux événements sont indépendants si savoir que l'un a été réalisé (ou pas) ne donne aucune information sur la réalisation de l'autre. Il faut faire attention au fait que l'indépendance d'événements est une notion qui dépend du choix de la probabilité (c'est pour cela que notre définition commence par se donner un espace probabilisé).</p>
        
        <article class="exemple">
            On lance un dé deux fois de suite. On prend $\Omega = [\![1,6]\!]^2$, on considère les événements
			$$\begin{align*}
			A &= \text{"on fait 6 au premier lancer"}\\
			 &= \{(6,y), y \in [\![1,6]\!]\}\\
			  &= \{(6,1), (6,2), (6,3), (6,4), (6,5), (6,6)\}
			\end{align*}$$
            et
			$$
			\begin{align*}
			B &= \text{"on fait 6 au second lancer"}\\
			&= \{(x,6), x \in [\![1,6]\!]\} \\
			&= \{(1,6), (2,6), (3,6), (4,6), (5,6), (6,6)\}\end{align*}$$
            Alors l'intersection de ces deux événements est
            $$A \cap B = \text{"on fait deux fois 6"} = \{(6,6)\}$$
            On a
            $$
            \begin{align*}
            \P(A \cap B) &= \frac{1}{36} \\
            &= \frac{1}{6} \times \frac{1}{6} \\
            &= \P(A) \times \P(B)
            \end{align*}
            $$
            Donc les événements $A$ et $B$ sont indépendants. On peut le comprendre intuitivement : connaître le résultat du premier lancer ne nous donne aucune information sur le résultat du second lancer. Maintenant considérons un troisième événement
            $$C = \text{"La somme des résultats des deux lancers fait 7"} = \{(x,y)\in [\![1,6]\!]^2, x+y = 7\}$$
            En énumérant tous les éléments de $C$, on trouve $\P(C) = \frac{6}{36} = \frac{1}{6}$. Par ailleurs, on a
            $$A \cap C = \{(6,1)\}$$
            et donc on a
            $$
            \begin{align*}
            \P(A \cap C) &= \frac{1}{36} \\
            &= \frac{1}{6} \times \frac{1}{6} \\
            &= \P(A) \times \P(C)
            \end{align*}
            $$
            donc $A$ et $C$ sont indépendants.
        </article>
        <h3>Indépendance pour plus de 2 événements</h3>
        <p>On peut étendre la notion d'indépendance à une famille de plusieurs événements mais il faudra alors distinguer deux notions : indépendants deux à deux, et indépendants mutuellement (ce qui est plus fort). Donnons la définition</p>
        <article class="definition"><strong>Indépendance 2 à 2, mutuelle</strong>
            <p>Étant donné un espace probabilisé $(\Omega, \mathcal{A}, \P)$, et une famille d'événements $(A_i)_{i \in I} \in \mathcal{A}^I$, on dira que les événements $A_i$ sont</p>
            <ul>
                <li><strong class="new">deux à deux indépendants</strong> si pour tous $i,j \in I$ avec $i \ne j$, les événements $A_i$ et $A_j$ sont indépendants, c'est-à-dire
                $$\P(A_i \cap A_j) = \P(A_i) \times \P(A_j)$$
                </li>
                <li><strong class="new">mutuellement indépendants</strong> si pour toute partie finie $J \subset I$, on a
                $$\P\left( \bigcap_{j \in J} A_j\right) = \prod_{j \in J} \P\left(A_j\right)$$
                </li>
            </ul>
        </article>
        <p>La notion d'indépendance mutuelle est plus forte que celle d'indépendance deux à deux. En effet, des événements qui sont mutuellement indépendants sont aussi 2 à 2 indépendants, mais il est possible pour des événements 2 à 2 indépendants de ne pas être mutuellement indépendants (c'est par exemple le cas des événements $A$, $B$ et $C$ de l'exemple précédent qui sont 2 à 2 indépdendants, mais pas mutuellement indépendants).</p>
        <p>Pour trois événements $A$, $B$ et $C$, dire qu'ils sont deux à deux indépendants revient à avoir les trois égalités :
            $$\P(A \cap B) = \P(A) \times \P(B), \qquad \P(B \cap C) = \P(B) \times \P(C), \qquad \P(C \cap A) = \P(C) \times \P(A)$$
        </p>
        <p>Pour que les événements soient mutuellement indépendants, il faut également vérifier une égalité supplémentaire :
            $$\P(A \cap B \cap C) = \P(A) \times \P(B) \times \P(C)$$
        </p>
        <p onclick="toggle_visibility('ind4ev');">Pouvez-vous écrire les 11 égalités que l'on obtient pour l'indépendance mutuelle de quatre événements $A$, $B$, $C$ et $D$ ?
		</p>
        <span id="ind4ev" class="sol"><p>Quatre événements $A$, $B$, $C$ et $D$ sont mutuellement indépendants s'ils sont indépendants 2 à 2 :</p>
		$$\begin{align*}
			\P(A \cap B) = \P(A) \times \P(B) && \qquad \P(B \cap C) = \P(B) \times \P(C) \\
			\\
			\qquad \P(C \cap D) = \P(C) \times \P(D) && \P(D \cap A) = \P(D) \times \P(A) \\
			\\
			\qquad \P(B \cap D) = \P(B) \times \P(D) && \P(A \cap C) = \P(A) \times \P(C)
		\end{align*}$$
        <p>indépendants 3 à 3 :</p>
		$$\begin{align*}
			\P(B \cap C \cap D) = \P(B) \times \P(C) \times \P(D) \\
			\\
			\qquad \P(A \cap C \cap D) = \P(A) \times \P(C) \times \P(D) \\
			\\
			\qquad \P(A \cap B \cap D) = \P(A) \times \P(B) \times \P(D) \\
			\\
			\qquad \P(A \cap B \cap C) = \P(A) \times \P(B) \times \P(C)
		\end{align*}$$
		<p>en enfin, indépendants 4 à 4 :</p>
		$$\P(A \cap B \cap C \cap D) = \P(A) \times \P(B) \times \P(C) \times \P(D)$$
	</span>
    </section>
    <section>
        <h2>Probabilité conditionnelle</h2>
        <p>La probabilité conditionnelle prend en compte comment la probabilité d'un événement est modifiée par une nouvelle information. Par exemple, imaginons que je prenne mon parapluie dès qu'il pleut. Si la probabilité qu'il pleuve est de $1/2$, alors la probabilité que je prenne mon parapluie est donc aussi $1/2$, mais la probabilité que je prenne mon parapluie sachant qu'il pleut est de $1$ !</p>
        <article class="definition"><strong>Probabilité conditionnelle</strong>
            <p>Soit $(\Omega, \mathcal{A}, \P)$ un espace probabilisé, et $A \in \mathcal{A}$ un événement de probabilité non nulle, alors l'application $\P_{A} : \mathcal{A} \to [0,1]$ définie pour tout $B \in \mathcal{A}$ par</p>
            <p>$$\P_{A}(B) = \P(B | A) = \frac{\P(A \cap B)}{\P(A)}$$</p>
            <p>est une probabilité, appelé <strong class="new">probabilité conditionnellement à $A$</strong>, ou probabilité sachant $A$.</p>
        </article>
        <p>On peut interprêter $\P(B | A)$ comme la probabilité de l'événement $B$ dès lors qu'on sait que l'évenement $A$ s'est produit. La formule de la probabilité conditionnelle est parfois utilisée sous la forme</p>
        <p>$$\P(A \cap B) = \P(B | A) \P(A)$$</p>
        <p>Ce qui fournit bien souvent un moyen de calculer la probabilité d'une intersection d'événements.</p>
        <article class="exemple">On lance un dé équilibré à 12 faces, c'est-à-dire que l'on prend $\Omega = [\![1,12]\!]$ et la probabilité uniforme. Considérons les événements
            $$A = \text{"la valeur du dé est un multiple de 3"} = \{3,6,9,12\}$$
            $$B =\text{"la valeur du dé est au moins 4"} = [\![4,12]\!]$$
            On a $A \cap B = \{6,9, 12\}$ et
            $$\P(B | A) = \frac{\P(A \cap B)}{\P(A)} = \frac{\ \frac{3}{12}\ }{\frac{4}{12}} = \frac{3}{4}$$
            On peut interpréter le résultat ainsi : Si on a tiré un multiple de 3 (événement $A$), c'est que l'on a tiré un 3, un 6, un 9 ou un 12. Parmi ces 4 possibilités équiprobables, 3 sont supérieures ou égales à 4. Donc si l'événement $A$ se réalise, on a une probabilité de $\frac{3}{4}$ pour que l'événement $B$ se réalise.
        </article>
        <h3>Probabilité conditionnelle et indépendance</h3>
        <p>On peut caractériser l'indépendance de deux événements en termes de probabilité conditionelle. On a en effet la proposition suivante.</p>
        <article class="prop">
            <p>Soit $(\Omega, \mathcal{A}, \P)$ un espace probabilisé, et $A, B \in \mathcal{A}$ deux événements. On suppose que $\P(A) \ne 0$. Alors $A$ et $B$ sont indépendant si et seulement si</p>
            <p>$$\P(B | A) = \P(B)$$</p>
        </article>
        <p>On peut interpréter l'égalité $\P(B | A) = \P(B)$ de la façon suivante : connaître $A$ n'apporte aucune nouvelle information sur $B$, donc la probabilité de $B$ est inchangée.</p>
        <h3 id="bayes">Formule de Bayes</h3>
        <article class="prop"><strong>Formule de Bayes</strong>
            <p>Soit $(\Omega, \mathcal{A}, \P)$ un espace probabilisé, et $A, B \in \mathcal{A}$ deux événements de probabilité non nulle. Alors on a</p>
            <p>$$\P(A | B) = \frac{\P(B | A) \cdot \P(A)}{\P(B)}$$</p>
        </article>
        <p>Voir <a href="td1#examen">Feuille 1</a> pour un exemple d'application de la formule.</p>
        <p>La preuve de la formule de Bayes n'est pas compliquée, mais cette égalité est étonnemment profonde dans l'interpretation qu'on peut lui donner, c'est notamment la base des statistiques inférentielles.</p>
        <h3>Formule des probabilites totales</h3>
        <p>Il est parfois intéressant de découper l'univers en plusieurs parties disjointes pour étudier les choses séparément dans chaque cas. Cela nous amène à poser la définition suivante.</p>
        
        <article class="definition" id="partition"><strong>Partition</strong>
            <p>Soit $(\Omega, \mathcal{A})$ un espace probabilisable, et $(A_i)_{i \in I}$ une famille d'événements de $\mathcal{A}$. On dit que la famille d'événements $(A_i)_{i \in I}$ <strong class="new">forme une partition</strong> de l'univers $\Omega$ (on parle également de <strong class="new">système exhaustif</strong>) si</p>
            <ol>
                <li><strong>Les événements sont disjoints deux à deux :</strong> Pour tout $i, j \in I$ avec $i\ne j$, on a $A_i \cap A_j = \emptyset$.
                </li>
                <li><strong>Les événements recouvrent l'univers :</strong>
                    $$\bigcup_{i \in I} A_i = \Omega$$
                </li>
            </ol>
        </article>
        
        <p>Un façon de le comprendre est que les événements $(A_i)_{i \in I}$ forment une partition de $\Omega$ si tout élément $\omega \in \Omega$ se trouve dans un et un seul des ensembles $A_i$.</p>
        <article class="exemple">Si $A \in \mathcal{A}$ est un événement quelconque, alors la famille $(A, \overline{A})$ forme une partition de $\Omega$. C'est un exemple simple mais relativement utile de partition.</article>
        <article class="exemple"><p>On lance deux dés à 6 faces. On prend donc $\Omega = [\![1,6]\!]^2$. Et pour $n \in [\![2,12]\!]$ on considère l'événement</p>
            <p>
                $$
                \begin{align*}
                    A_n &= \text{"la somme des valeurs de deux dés fait } n {"} \\
                    &= \set{(x,y) \in \Omega, x + y = n}
                \end{align*}
                $$
            </p>
            <p>Alors la famille $(A_n)_{1 \le n \le 12}$ constitue une partition de $\Omega$ : en effet, si $\omega = (x,y) \in A_i \cap A_j$, alors $x +y = i = j$ donc $i = j$. Donc les $A_i$ sont deux à deux disjoints. Et si $\omega = (x,y) \in \Omega$, alors $\omega \in A_{x+y}$, donc les $A_i$ recouvrent bien tout $\Omega$.</p>
        </article>
        
        <article class="prop" id="probas_totales"><strong>Formule des probabilités totales</strong>
            <p>Soit $(\Omega, \mathcal{A}, \P)$ un espace probabilisé, et $(A_i)_{i \in I}$ une partition de $\Omega$, avec $I$ un ensemble fini ou dénombrable. Pour tout événement $B \in \mathcal{A}$, on a</p>
        $$ \P(B) = \sum_{i \in I} \P(B \cap A_i)$$
        <p>Et si de plus on suppose que $P(A_i) \ne 0$ pour tout $i \in I$, alors on peut écrire</p>
        $$ \P(B) = \sum_{i \in I} \P(B | A_i) \cdot \P(A_i)$$
        </article>
        
        <article class="exemple">Si $A \in \mathcal{A}$ est un événement de probabilité différente de $0$ et de $1$, alors on a pour tout événement $B \in \mathcal{A}$ la formule
        $$\P(B) = \P(B | A) \cdot \P(A) + \P(B | \overline{A}) \cdot \P(\overline{A})$$
        </article>
        
        <p>En combinant la formule de Bayes avec celle des probabilités totales, on obtient une formule assez utile que nous donnons dans la proposition suivante.</p>
        <article class="prop">
            <p>Soit $(\Omega, \mathcal{A}, \P)$ un espace probabilisé, et $(A_i)_{i \in I}$ une partition de $\Omega$ par des ensembles de probabilité non nulle, avec $I$ un ensemble fini ou dénombrable. Pour tout événement $B \in \mathcal{A}$ de probabilité non nulle, on a</p>
            <p>$$\P(A_i | B) = \frac{\P(B | A_i) \cdot \P(A_i)}{\sum_{j \in I} \P(B | A_j) \cdot \P(A_j)}$$</p>
        </article>
    </section>
    <nav>
        <a href="chap2">Chapitre suivant : Variables aléatoires >></a>
    </nav>
</div>   